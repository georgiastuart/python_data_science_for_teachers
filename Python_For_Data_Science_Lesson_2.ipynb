{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WeTeach_Python Day 4 Lesson 1",
      "provenance": [],
      "authorship_tag": "ABX9TyMa1L7lPB9fYzumtrNvoBTd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/georgiastuart/python_data_science_for_teachers/blob/main/Python_For_Data_Science_Lesson_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWiKxsW_QwbJ"
      },
      "source": [
        "# Python for Data Science Lesson 2: Introduction to Regression Neural Networks\n",
        "\n",
        "This lesson is inspired by [this notebook](https://www.kaggle.com/arunkumarramanan/tensorflow-tutorial-and-housing-price-prediction) on Kaggle. \n",
        "\n",
        "We will use the [Tensorflow](https://www.tensorflow.org/api_docs/python/tf) Python library in order to build a neural network to predict housing prices (in 1970s Boston). \n",
        "\n",
        "## What is a Neural Network?\n",
        "\n",
        "A *neural network* is a mathematical structure composed of layers of neurons inspired by how our brains work. \n",
        "\n",
        "[This 3Blue1Brown video](https://www.youtube.com/watch?v=aircAruvnKk) is a great introduction to the structure of neural networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK-AagUcQdoN"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb080T9IU0Di"
      },
      "source": [
        "## Acquiring Data\n",
        "\n",
        "For this tutorial, we'll use data that's provided by the `keras` module itself. We'll load a *training set* and its associated *labels* (output) and a *test set* with labels. \n",
        "\n",
        "The data is [Boston Housing Price Data](https://keras.io/api/datasets/boston_housing/) which is composed of 13 factors that may predict the price of a house in Boston. The keras dataset is simply a numpy array, but we can see what each column refers to [here](http://lib.stat.cmu.edu/datasets/boston)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeUyrOHXUUIt"
      },
      "source": [
        "(train_features, train_labels), (test_features, test_labels) = keras.datasets.boston_housing.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WOcfslnVTqf"
      },
      "source": [
        "Lets look at the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnpGTPQGVVLh"
      },
      "source": [
        "print(train_features.shape)\n",
        "print(train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI0zNiTpVQMW"
      },
      "source": [
        "As you can see, we have 404 data observations and 13 pieces of information \n",
        "\n",
        "Now we need to set up the data for training the network. If we look at the data, we see that each line of data is all different magnitudes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nE3kW59VEPu"
      },
      "source": [
        "print(train_features[0, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8TnXxG1UseX"
      },
      "source": [
        "Neural networks are more effectively trained when data is *normalized*, so we're going to scale each column so that they're on the same scale.\n",
        "\n",
        "We do that by calculating the *z-score* of each datapoint (the number of standard deviations away from the mean):\n",
        "\n",
        "$$\\frac{x - \\bar{x}}{\\sigma}$$\n",
        "\n",
        "where $x$ is a data point, $\\bar{x}$ is the mean of the feature, and $\\sigma$ is the standard deviation of the feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNLrdecbUd7e"
      },
      "source": [
        "train_mean = np.mean(train_features, axis=0)\n",
        "print(train_mean.shape, train_mean)\n",
        "train_std = np.std(train_features, axis=0)\n",
        "\n",
        "normalized_train_features = (train_features - train_mean) / train_std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_mean = np.mean(train_labels)\n",
        "label_std = np.std(train_labels)\n",
        "normalized_train_labels = (train_labels - label_mean) / label_std"
      ],
      "metadata": {
        "id": "BEIzMsi2dlPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE2b5PRGVkx6"
      },
      "source": [
        "Now, if we look at the mean of the normalized train features, it will be zero for all features (within floating point error) and the standard deviation will be 1 for all features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au5BfryGVjEz"
      },
      "source": [
        "print(np.mean(normalized_train_features, axis=0))\n",
        "print(np.std(normalized_train_features, axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI6NdR66V8mu"
      },
      "source": [
        "Now that our data is normalized, we need to build the structure of our neural network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xdx6Fu_VGEa"
      },
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "                            Dense(20, activation=tf.nn.relu, input_shape=[normalized_train_features.shape[1]]),\n",
        "                            Dense(1)\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=['mae', 'mse'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewQpzxfAW7JB"
      },
      "source": [
        "Now we need to train our neural network. \n",
        "\n",
        "Here's the next video in the [3Blue1Brown Neural Network series](https://www.youtube.com/watch?v=IHZwWFHWa-w)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVi4As1zWnnD"
      },
      "source": [
        "model = build_model()\n",
        "history = model.fit(normalized_train_features, normalized_train_labels, epochs=1000, validation_split=0.1, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAgbAYZqXa5z"
      },
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6jAUSn2YdP-"
      },
      "source": [
        "plt.plot(hist['mse'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCMUPI1DY9tH"
      },
      "source": [
        "Now lets look at a few pieces of test data and see what our network preducts!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0XWHhOgYmDA"
      },
      "source": [
        "normalized_test_features = (test_features - train_mean) / train_std\n",
        "normalized_test_features.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uwhxz4ZyZK8F"
      },
      "source": [
        "result = model.predict(normalized_test_features)\n",
        "print(result.shape)\n",
        "\n",
        "plt.scatter(test_labels, result[:, 0] * label_std + label_mean)\n",
        "plt.xlabel('True Value (1000s of $)')\n",
        "plt.ylabel('Predicted Value (1000s of $)');\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDdDxgbYZaVN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}